system {
    spark {
        path {
            # uncomment the following section if you want to extract an archive on every run
            archive = {
                src = ${app.path.downloads}"/spark-1.3.1-bin-hadoop2.6.tgz"
                dst = ${app.path.systems}
            }
            home = ${app.path.systems}"/spark-1.3.1-bin-hadoop2.6"
        }
        config {
            # put list of slaves
            slaves = ${system.default.config.slaves}

            # spark-env.sh entries
            env {
                HADOOP_CONF_DIR = ${system.hadoop-2.path.config}
                SPARK_EXECUTOR_MEMORY = "256m"
                SPARK_WORKER_MEMORY = "256m"
            }
            # spark-defaults.conf
            defaults {
                spark.master = "spark://"${runtime.hostname}":7077"
                spark.executor.memory = "256m"
                spark.eventLog.enabled = "true"
                spark.eventLog.dir = "file://"${system.spark.path.log}
            }
        }
    }
}